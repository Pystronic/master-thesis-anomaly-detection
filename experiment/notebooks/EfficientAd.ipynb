{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mDWkebQlGMU_"},"outputs":[],"source":["# Early permission request for google drive\n","from google.colab import drive\n","drive.mount('/content/drive', timeout_ms=18*60*3600)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-QhlJGepp_fR"},"outputs":[],"source":["# Install dependencies\n","%%shell\n","apt-get -qq remove python3-blinker --quiet\n","pip uninstall torchaudio fastai -y --quiet\n","pip install git+https://github.com/Pystronic/master-thesis-anomaly-detection.git#subdirectory=experiment/thesis_library --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JSpq6Btse_8w"},"outputs":[],"source":["# Imports\n","from thesis_library.data.miad_dataset import MIAD_CATEGORIES\n","from thesis_library.data.miad_datamodule import MIAD\n","from thesis_library.metrics import image, pixel\n","from thesis_library.metrics.util import  calculate_AD_metrics\n","from thesis_library.LimitedImageVisualizer import LimitedImageVisualizer\n","\n","import time\n","from pathlib import Path\n","from datetime import datetime\n","\n","import torch\n","from anomalib.callbacks import ModelCheckpoint\n","from anomalib.data.utils import ValSplitMode\n","from anomalib.deploy import ExportType\n","from anomalib.metrics import Evaluator\n","from anomalib.engine import Engine\n","from lightning.pytorch.loggers import CSVLogger\n","from pandas import DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LZSxL8LpBx6Z"},"outputs":[],"source":["# Fix pytorch-lightning bug on export\n","# https://github.com/Lightning-AI/pytorch-lightning/issues/17124\n","def getstate_patch(*_):\n","    return {}\n","from torch.utils.data.dataloader import _BaseDataLoaderIter\n","_BaseDataLoaderIter.__getstate__ = getstate_patch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LH0nGrTucVNJ"},"outputs":[],"source":["# Optimization for A100, H100, etc\n","# Less precission but more performance\n","torch.backends.cuda.matmul.allow_tf32 = True\n","torch.set_float32_matmul_precision(\"high\")"]},{"cell_type":"markdown","metadata":{"id":"rZgeUoEEfFEs"},"source":["## Auswahl von Modell und Kategorie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nbO0tSnCfDbM"},"outputs":[],"source":["# Set category for training / testing\n","CURRENT_CATEGORY = MIAD_CATEGORIES[0]\n","print(f\"Selected category {CURRENT_CATEGORY} from {MIAD_CATEGORIES}\")\n","\n","\n","CURRENT_MODEL = \"EfficientAd_10_Epoch\"\n","LOAD_MODEL_PATH = None#f\"/content/drive/MyDrive/{CURRENT_MODEL}/{CURRENT_CATEGORY}/model/weights/torch/{CURRENT_MODEL}.pt\"\n","MODEL_EPOCHS = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82NiN67h48Qh"},"outputs":[],"source":["# Clear data of previous run\n","!rm -r results/*\n","!rm -r datasets/MIAD/*.zip*"]},{"cell_type":"markdown","metadata":{"id":"HhO4vWckeo0q"},"source":["## Vorbereitung von Ordnern und Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qcxWOg6mprDH"},"outputs":[],"source":["# Prepare google drive directories\n","from pathlib import Path\n","GDRIVE_DIR = Path(\"/content/drive/MyDrive\")\n","LOCAL_DIR = Path(\"results\")\n","MIAD_GDRIVE_DIR = GDRIVE_DIR / \"MIAD\"\n","MIAD_GDRIVE_CATEGORY_DIR = MIAD_GDRIVE_DIR / CURRENT_CATEGORY\n","print(MIAD_GDRIVE_CATEGORY_DIR)\n","\n","LOCAL_CHECKPOINT_DIR = LOCAL_DIR / \"checkpoints\"\n","LOCAL_RESULT_DIR = LOCAL_DIR / \"results\"\n","\n","GDRIVE_RESULT_DIR = GDRIVE_DIR / CURRENT_MODEL / CURRENT_CATEGORY\n","MODEL_EXPORT_DIR = GDRIVE_RESULT_DIR / \"model\"\n","print(LOCAL_CHECKPOINT_DIR)\n","print(LOCAL_RESULT_DIR)\n","print(MODEL_EXPORT_DIR)\n","print(GDRIVE_RESULT_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YSlUYAl5_JPY"},"outputs":[],"source":["# Prepare local dataset directories\n","MIAD_DIR = Path(\"datasets/MIAD\")\n","MIAD_CATEGORY_DIR = MIAD_DIR / CURRENT_CATEGORY\n","MIAD_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Prepare result directories\n","LOCAL_CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n","LOCAL_RESULT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","MODEL_EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n","GDRIVE_RESULT_DIR.mkdir(parents=True, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqvo3dRI8b-Q"},"outputs":[],"source":["# Extract files locally from GDrive\n","!cp $MIAD_GDRIVE_CATEGORY_DIR/*.zip* $MIAD_DIR\n","!7z x \"$MIAD_DIR/*.zip*\" -o$MIAD_DIR -y -bd"]},{"cell_type":"markdown","metadata":{"id":"ep3Z6GxCewxk"},"source":["## Vorbereitung f√ºr Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kvt9DJbyBgrp"},"outputs":[],"source":["# Prepare logging and saving checkpoints\n","logger = CSVLogger(LOCAL_RESULT_DIR, name=f\"run_log_{datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\")\n","\n","checkpoint_callback = ModelCheckpoint(\n","    dirpath=LOCAL_CHECKPOINT_DIR,\n","    filename=\"best-{epoch:02d}-{IMG_AUROC:.3f}\",\n","    monitor=\"IMG_AUROC\",\n","    mode=\"max\",\n","    save_top_k=3,\n","    every_n_epochs=10,\n","    save_weights_only=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xChJlAs5sZKw"},"outputs":[],"source":["# Load datamodule as object\n","datamodule = MIAD(\n","    root=MIAD_DIR,\n","    category=CURRENT_CATEGORY,\n","    val_split_mode=ValSplitMode.FROM_TEST,\n","    val_split_ratio=0.1,\n","    num_workers=2,\n","    seed=4232,\n","    # Modify batch size to optimizie GPU training\n","    # Set to 1 since efficentAd requires it\n","    train_batch_size=1,\n","    eval_batch_size=8\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hcVvoPi0QQ_z"},"outputs":[],"source":["# Prepare metrics and evaluator\n","test_metrics = [\n","    *image.get_metrics(),\n","    *pixel.get_metrics(),\n","]\n","\n","evaluator = Evaluator(\n","    test_metrics=test_metrics,\n","    val_metrics=pixel.get_val_metrics(),\n","    # Deactivated since this causes errors during testing\n","    compute_on_cpu=False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0LFnICHR7kqC"},"outputs":[],"source":["# Only visualize the first 50 images per category\n","# to reduce performance overhead in test\n","visualizer = LimitedImageVisualizer(50, field_size=(512, 512))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UAG4udF8hXQY"},"outputs":[],"source":["from anomalib.models import EfficientAd\n","# Set pre-processor to the correct size\n","pre_processor = EfficientAd.configure_pre_processor((512, 512))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ejQVK3RQba-"},"outputs":[],"source":["# Setup engine for training / testing\n","engine = Engine(\n","    max_epochs=MODEL_EPOCHS,\n","    callbacks=[checkpoint_callback],\n","    logger=logger,\n","    default_root_dir=LOCAL_RESULT_DIR,\n","    # Use bfloat precision to increase fitting / interference performance\n","    precision=\"bf16-mixed\",\n","    # Do not invest more than 16 hours of training time\n","    # Batch size of 1 trains very very slowly\n","    max_time=\"00:16:00:00\",\n","    log_every_n_steps=400\n",")"]},{"cell_type":"markdown","metadata":{"id":"0cimZM6WCclZ"},"source":["## Model-Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJM7rVjRCZrn"},"outputs":[],"source":["from anomalib.models.image.efficient_ad.torch_model import EfficientAdModelSize\n","model = EfficientAd(evaluator=evaluator, visualizer=visualizer, pre_processor=pre_processor, model_size=EfficientAdModelSize.M)\n","\n","if LOAD_MODEL_PATH is not None:\n","    # Load model weight. We can trust them, since we exported it ourselves\n","    model.load_state_dict(torch.load(LOAD_MODEL_PATH, weights_only=False), strict=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5h56RLjhBv1k"},"outputs":[],"source":["# Prepare auxiliary data with same size as the dataset\n","model.prepare_imagenette_data((512, 512))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mrjZyCXWBpxv"},"outputs":[],"source":["# Prepare EfficientAD pre-trained model\n","model.prepare_pretrained_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2NwegPC-CoPy"},"outputs":[],"source":["# Train the model\n","if LOAD_MODEL_PATH is None:\n","    engine.fit(datamodule=datamodule, model=model)\n","    engine.export(model, ExportType.TORCH, model_file_name=CURRENT_MODEL, export_root=MODEL_EXPORT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"JvCLNa3Ie0-V"},"source":["# Validierung des Modells"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fxP4cHxcSwR_"},"outputs":[],"source":["# Returned as single element list and approximate performance\n","test_start = time.perf_counter()\n","test_result = engine.test(\n","    datamodule=datamodule,\n","    model=model\n",")[0]\n","test_end = time.perf_counter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxaGaKzHHRsk"},"outputs":[],"source":["# Calculate AD metrics\n","test_result = calculate_AD_metrics(test_result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GaIBA-jBSyH_"},"outputs":[],"source":["# Calculate compound metrics and export results\n","result_frame = DataFrame.from_records([dict(test_result)])\n","result_frame[\"model\"] = CURRENT_MODEL\n","result_frame[\"category\"] = CURRENT_CATEGORY\n","result_frame[\"rel_images_per_second\"] = [(test_end - test_start) / len(datamodule.test_data.samples)]\n","result_frame.to_csv(LOCAL_RESULT_DIR / \"test_results.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4z2uMbxLtPCx"},"outputs":[],"source":["# Move local files to drive\n","!cp -r $LOCAL_DIR/* $GDRIVE_RESULT_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E94ZzhbATG_H"},"outputs":[],"source":["# Stop the colab runtime\n","from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPz5bL8ugxVVMt3feqIe15e"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}